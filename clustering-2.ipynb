{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import operator\n",
    "\n",
    "from scipy.io import arff\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ops():\n",
    "    return {'>': operator.gt, '<': operator.lt }\n",
    "\n",
    "def determine_eps(data):\n",
    "    \"\"\"\n",
    "    Determine a suitable value for eps for use with DBSCAN\n",
    "    \n",
    "    Args:\n",
    "        data: zipped list containing data points, like [(x1,y1), (x2,y2), ...]\n",
    "    \n",
    "    Returns:\n",
    "        An eps value greater than the distance separating 85% of points from each other.\n",
    "    \"\"\"\n",
    "    tree = neighbors.KDTree(data)\n",
    "    distances = [] # average distance to 5 closest points\n",
    "    \n",
    "    for (i, point) in enumerate(data):\n",
    "        dist, _ = tree.query(data[i:i+1], k=5+1) # k=1 compares distance to itself\n",
    "        distances.append(np.mean(dist[0][1:]))\n",
    "    \n",
    "    \"\"\" Optional historgram for sanity check \"\"\"\n",
    "    # plt.hist(distances, bins=50)\n",
    "    # plt.show()\n",
    "\n",
    "    \"\"\" Optional scatter plot for sanity check \"\"\"\n",
    "    # plt.scatter(np.linspace(1,len(distances),len(distances)), sorted(distances), s=1)\n",
    "    # plt.show()\n",
    "    \n",
    "    p85 = int(np.floor(len(distances) * 0.85))\n",
    "    \n",
    "    # Sorting distances effectively gives the cumulative distribution \"function\".\n",
    "    return sorted(distances)[p85]\n",
    "\n",
    "def run(algorithm, data, metric, metric_params):    \n",
    "    best_score = metric_params['best_score']\n",
    "    score = metric_params['score']\n",
    "    op = get_ops()[metric_params['op']]\n",
    "    \n",
    "    results = []\n",
    "    times = []\n",
    "    best_model = 1\n",
    "    \n",
    "    for alg in algorithm:\n",
    "        time_start = time.time()\n",
    "        \n",
    "        model = alg.fit(data)\n",
    "        \n",
    "        time_post_cluster = time.time()\n",
    "        \n",
    "        score = metric(data, model.labels_)\n",
    "        \n",
    "        time_post_score = time.time()\n",
    "        \n",
    "        if op(score, best_score):\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "        \n",
    "        results.append((len(set(model.labels_)), score))\n",
    "        times.append((time_start, time_post_cluster, time_post_score))\n",
    "    \n",
    "    best_n_clusters_guess = metric_params['fn'](results, key=lambda r: r[1])[0]\n",
    "    total_exec_time = times[-1][2]-times[0][0]\n",
    "\n",
    "    return best_n_clusters_guess, best_model, total_exec_time\n",
    "\n",
    "silhouette_mp = {\n",
    "    'best_score': -1,  # Lower bound for Silhouette coefficient (higher is better)\n",
    "    'score': 0,        # Initial score\n",
    "    'op': '>',         # Score comparison operator\n",
    "    'fn': max\n",
    "}\n",
    "\n",
    "cal_hara_mp = {\n",
    "    'best_score': -1,  # Assumed lower bound for CH index (higher is better)\n",
    "    'score': 0,        # Initial score\n",
    "    'op': '>',         # Score comparison operator\n",
    "    'fn': max\n",
    "}\n",
    "\n",
    "dav_boul_mp = {\n",
    "    'best_score': 99999,   # Assumed upper bound for DB index (lower is better)\n",
    "    'score': 99999.1,        # Initial score\n",
    "    'op': '<',         # Score comparison operator\n",
    "    'fn': min    \n",
    "}\n",
    "\n",
    "def print_results(n_clusters, model, timing, algorithm, metric):\n",
    "    print(\"Algorithm: \", algorithm)\n",
    "    print(\"Metric: \", metric)\n",
    "    print(\"Number of clusters: \", n_clusters)\n",
    "    print(f\"Time: {timing} seconds\")\n",
    "\n",
    "def plot_results(data, model, algorithm):\n",
    "    if algorithm == 'K-Means':\n",
    "        center_x = [point[0] for point in model.cluster_centers_]\n",
    "        center_y = [point[1] for point in model.cluster_centers_]\n",
    "    \n",
    "    plt.scatter(data[\"x\"], data[\"y\"], c=model.labels_, cmap='rainbow')\n",
    "    if algorithm == \"K-Means\":\n",
    "        plt.scatter(center_x, center_y, marker=\"x\", c=\"000000\")\n",
    "    plt.title(f\"Data after clustering with {algorithm}\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_results_3D(data, model, algorithm):\n",
    "    if algorithm == 'K-Means':\n",
    "        center_x = [point[0] for point in model.cluster_centers_]\n",
    "        center_y = [point[1] for point in model.cluster_centers_]\n",
    "        center_z = [point[2] for point in model.cluster_centers_]\n",
    "\n",
    "    threedee = plt.figure()\n",
    "    ax = threedee.add_subplot(projection=\"3d\")\n",
    "    ax.scatter(data[\"x\"], data[\"y\"], data[\"z\"], c=model.labels_, cmap='rainbow')\n",
    "    if algorithm == \"K-Means\":\n",
    "        ax.scatter(center_x, center_y, center_z, marker=\"x\", c=\"000000\")\n",
    "    plt.title(f\"Data after clustering with {algorithm}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2d = pd.read_csv(\"./dataset/tr.data\", sep=\" \", names=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2d.plot.scatter(x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Means on 2D datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_ = [cluster.KMeans(n_clusters=i, init=\"k-means++\") for i in range(2, 20+1)]\n",
    "\n",
    "n_clusters, model, timing = run(kmeans_, df2d, metrics.davies_bouldin_score, dav_boul_mp)\n",
    "print_results(n_clusters, model, timing, \"K-Means\", \"Davies-Bouldin score\")\n",
    "plot_results(df2d, model, \"K-Means\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative clustering on 2D datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_ward = [cluster.AgglomerativeClustering(n_clusters=i, linkage='ward') for i in range(2, 20+1)]\n",
    "\n",
    "n_clusters, model, timing = run(agglo_ward, df2d, metrics.davies_bouldin_score, dav_boul_mp)\n",
    "print_results(n_clusters, model, timing, \"Agglomerative Clustering\", \"Davies-Bouldin score\")\n",
    "plot_results(df2d, model, \"Agglomerative Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN on 2D datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = determine_eps(list(zip(df2d['x'], df2d['y'])))\n",
    "dbscan_ = [cluster.DBSCAN(eps=eps, min_samples=i) for i in range(2, 20+1)]\n",
    "\n",
    "n_clusters, model, timing = run(dbscan_, df2d, metrics.davies_bouldin_score, dav_boul_mp)\n",
    "print_results(n_clusters, model, timing, \"DBSCAN\", \"Davies-Bouldin score\")\n",
    "plot_results(df2d, model, \"DBSCAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = cluster.DBSCAN(eps=0.3, min_samples=7).fit(df2d)\n",
    "\n",
    "plt.scatter(df2d[\"x\"], df2d[\"y\"], c=dbscan.labels_, cmap='rainbow')\n",
    "plt.title(\"Data after clustering with DBSCAN manually (eps = 0.3, min_samples = 7)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN on 2D datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_ = [hdbscan.HDBSCAN(min_cluster_size=i) for i in range(2, 20+1)]\n",
    "\n",
    "n_clusters, model, timing = run(hdbscan_, df2d, metrics.davies_bouldin_score, dav_boul_mp)\n",
    "print_results(n_clusters, model, timing, \"HDBSCAN\", \"Davies-Bouldin score\")\n",
    "plot_results(df2d, model, \"HDBSCAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maa = hdbscan.HDBSCAN(min_cluster_size=4).fit(df2d)\n",
    "\n",
    "plt.scatter(df2d[\"x\"], df2d[\"y\"], c=maa.labels_, cmap='rainbow')\n",
    "plt.title(\"Data after clustering with HDBSCAN manually (min_cluster_size = 4)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3d = pd.read_csv(\"./dataset/a.data\", sep=\"\\t\", names=[\"x\", \"y\", \"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threedee = plt.figure()\n",
    "ax = threedee.add_subplot(projection=\"3d\")\n",
    "ax.scatter(df3d[\"x\"], df3d[\"y\"], df3d[\"z\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Means on 3D datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_ = [cluster.KMeans(n_clusters=i, init=\"k-means++\") for i in range(2, 20+1)]\n",
    "\n",
    "n_clusters, model, timing = run(kmeans_, df3d, metrics.davies_bouldin_score, dav_boul_mp)\n",
    "print_results(n_clusters, model, timing, \"K-Means\", \"Davies-Bouldin score\")\n",
    "plot_results_3D(df3d, model, \"K-Means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_ = cluster.KMeans(n_clusters=2, init=\"k-means++\").fit(df3d)\n",
    "\n",
    "threedee = plt.figure()\n",
    "ax = threedee.add_subplot(projection=\"3d\")\n",
    "ax.scatter(df3d[\"x\"], df3d[\"y\"], df3d[\"z\"], c=kmeans_.labels_, cmap='rainbow')\n",
    "plt.title(f\"Data after clustering with K-Means manually (n_clusters = 2)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative clustering on 3D datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_ward = [cluster.AgglomerativeClustering(n_clusters=i, linkage='ward') for i in range(2, 20+1)]\n",
    "\n",
    "n_clusters, model, timing = run(agglo_ward, df3d, metrics.davies_bouldin_score, dav_boul_mp)\n",
    "print_results(n_clusters, model, timing, \"Agglomerative Clustering\", \"Davies-Bouldin score\")\n",
    "plot_results_3D(df3d, model, \"Agglomerative Clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_ward = cluster.AgglomerativeClustering(n_clusters=2, linkage='ward').fit(df3d)\n",
    "\n",
    "threedee = plt.figure()\n",
    "ax = threedee.add_subplot(projection=\"3d\")\n",
    "ax.scatter(df3d[\"x\"], df3d[\"y\"], df3d[\"z\"], c=kmeans_.labels_, cmap='rainbow')\n",
    "plt.title(f\"Data after clustering with Agglomerative Clustering manually (n_clusters = 2)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN on 3D datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = determine_eps(list(zip(df3d['x'], df3d['y'], df3d['z'])))\n",
    "dbscan_ = [cluster.DBSCAN(eps=eps, min_samples=i) for i in range(2, 20+1)]\n",
    "\n",
    "n_clusters, model, timing = run(dbscan_, df3d, metrics.davies_bouldin_score, dav_boul_mp)\n",
    "print_results(n_clusters, model, timing, \"DBSCAN\", \"Davies-Bouldin score\")\n",
    "plot_results_3D(df3d, model, \"DBSCAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_ = cluster.DBSCAN(eps=5, min_samples=15).fit(df3d)\n",
    "\n",
    "threedee = plt.figure()\n",
    "ax = threedee.add_subplot(projection=\"3d\")\n",
    "ax.scatter(df3d[\"x\"], df3d[\"y\"], df3d[\"z\"], c=dbscan_.labels_, cmap='rainbow')\n",
    "plt.title(f\"Data after clustering with DBSCAN manually (eps = 5, min_samples = 15)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN on 3D datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_ = [hdbscan.HDBSCAN(min_cluster_size=i) for i in range(2, 20+1)]\n",
    "\n",
    "n_clusters, model, timing = run(hdbscan_, df3d, metrics.davies_bouldin_score, dav_boul_mp)\n",
    "print_results(n_clusters, model, timing, \"HDBSCAN\", \"Davies-Bouldin score\")\n",
    "plot_results_3D(df3d, model, \"HDBSCAN\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_ = hdbscan.HDBSCAN(min_cluster_size=5).fit(df3d)\n",
    "\n",
    "threedee = plt.figure()\n",
    "ax = threedee.add_subplot(projection=\"3d\")\n",
    "ax.scatter(df3d[\"x\"], df3d[\"y\"], df3d[\"z\"], c=hdbscan_.labels_, cmap='rainbow')\n",
    "plt.title(f\"Data after clustering with HDBSCAN manually (min_cluster_size = 5)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive 3D plot for fun and profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df3d, x=\"x\", y=\"y\", z=\"z\", color=hdbscan_.labels_)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
